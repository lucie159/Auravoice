import torch
import librosa
from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor


class EmotionModel:
    def __init__(self, model_dir="./models/emotion"):
        self.model_dir = model_dir
        self.model = None
        self.processor = None
        self.id2label = {
            "0": "Anger",
            "1": "Calm",
            "2": "Disgust",
            "3": "Fear",
            "4": "Happy",
            "5": "Neutral",
            "6": "Sad",
            "7": "Surprised"
        }

    async def load(self):
        """Load HuggingFace model"""
        self.processor = Wav2Vec2FeatureExtractor.from_pretrained(self.model_dir)
        self.model = Wav2Vec2ForSequenceClassification.from_pretrained(self.model_dir)
        self.model.eval()

    async def predict(self, audio_path: str):
        """Predict emotion from audio file"""
        speech, sr = librosa.load(audio_path, sr=16000)

        inputs = self.processor(
            speech,
            sampling_rate=16000,
            return_tensors="pt",
            padding=True
        )

        with torch.no_grad():
            logits = self.model(**inputs).logits
            probs = torch.nn.functional.softmax(logits, dim=1).squeeze().tolist()

        # best prediction
        max_idx = str(int(torch.argmax(logits)))

        return {
            "emotion": self.id2label[max_idx],
            "scores": {self.id2label[str(i)]: float(probs[i]) for i in range(len(probs))}
        }
