# AuraVoice Backend

Backend FastAPI pour le copilote Ã©motionnel AuraVoice.

## ğŸš€ DÃ©marrage Rapide

### Option 1: Docker (RecommandÃ©)

\`\`\`bash
# DÃ©marrer avec PostgreSQL
docker-compose up -d

# Ou avec MongoDB
DATABASE_TYPE=mongodb docker-compose up -d
\`\`\`

### Option 2: Installation Manuelle

\`\`\`bash
# CrÃ©er l'environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou: venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# Copier et configurer .env
cp .env.example .env
# Ã‰diter .env avec vos paramÃ¨tres

# DÃ©marrer le serveur
python -m app.main
\`\`\`

## ğŸ“ Structure

\`\`\`
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â”œâ”€â”€ main.py             # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ database/           # Connexions PostgreSQL/MongoDB
â”‚   â”œâ”€â”€ models/             # SchÃ©mas Pydantic et modÃ¨les ORM
â”‚   â”œâ”€â”€ routers/            # Routes API
â”‚   â””â”€â”€ services/           # Services mÃ©tier
â”œâ”€â”€ models/                 # Placez votre modÃ¨le IA ici
â”œâ”€â”€ uploads/                # Fichiers audio temporaires
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
\`\`\`

## ğŸ”Œ IntÃ©gration de Votre ModÃ¨le IA

### Option 1: ModÃ¨le ONNX Local

1. Placez votre modÃ¨le dans `models/emotion_model.onnx`
2. Ã‰ditez `app/services/emotion_ai_service.py`:
   - Adaptez la mÃ©thode `predict()` de `ONNXEmotionModel`
   - Ajustez le prÃ©traitement selon votre modÃ¨le
   - Modifiez le mapping des sorties

\`\`\`python
# Dans ONNXEmotionModel.predict():
# 1. PrÃ©traitement audio (mel-spectrogramme, MFCC, etc.)
# 2. Format d'entrÃ©e de votre modÃ¨le
# 3. Mapping des sorties vers EmotionType
\`\`\`

3. Configurez `.env`:
\`\`\`env
EMOTION_MODEL_TYPE=local
EMOTION_MODEL_PATH=./models/emotion_model.onnx
\`\`\`

### Option 2: ModÃ¨le HuggingFace

1. Configurez `.env`:
\`\`\`env
EMOTION_MODEL_TYPE=huggingface
EMOTION_MODEL_NAME=superb/wav2vec2-base-superb-er
\`\`\`

2. Adaptez le mapping des labels si nÃ©cessaire dans `HuggingFaceEmotionModel._map_label_to_emotion()`

### Option 3: API Externe

CrÃ©ez une nouvelle classe hÃ©ritant de `EmotionModelBase`:

\`\`\`python
class APIEmotionModel(EmotionModelBase):
    async def predict(self, audio_chunk, sample_rate):
        # Appeler votre API
        response = await httpx.post("https://your-api.com/predict", ...)
        return EmotionType(response["emotion"]), response["confidence"]
\`\`\`

## ğŸ“¡ API Endpoints

### Authentification
- `POST /api/auth/login` - Connexion
- `POST /api/auth/register` - Inscription
- `GET /api/auth/me` - Utilisateur courant

### Appels
- `GET /api/calls/active` - Appels en cours (superviseur)
- `POST /api/calls/start` - DÃ©marrer un appel
- `POST /api/calls/{id}/end` - Terminer un appel

### Analyse
- `POST /api/analyze` - Analyser un fichier audio

### Rapports
- `GET /api/reports` - Liste des rapports (avec filtres)
- `POST /api/reports` - CrÃ©er un rapport
- `GET /api/reports/{id}` - DÃ©tail d'un rapport

### WebSocket
- `WS /ws/supervisor?token=...&team_id=...` - Temps rÃ©el superviseur
- `WS /ws/agent?token=...&agent_id=...` - Temps rÃ©el agent

## ğŸ”§ Configuration Frontend

Mettez Ã  jour le frontend pour pointer vers ce backend:

\`\`\`env
# Dans le frontend Next.js
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_USE_REAL_API=true
\`\`\`

## ğŸ“Š Base de DonnÃ©es

### PostgreSQL (RecommandÃ© pour la production)
\`\`\`sql
-- Les tables sont crÃ©Ã©es automatiquement au dÃ©marrage
-- Voir app/models/postgres_models.py pour le schÃ©ma
\`\`\`

### MongoDB (Alternative NoSQL)
\`\`\`javascript
// Collections crÃ©Ã©es automatiquement:
// - users
// - call_reports  
// - active_calls
\`\`\`

## ğŸ”’ SÃ©curitÃ©

- Les mots de passe sont hashÃ©s avec bcrypt
- Authentification JWT avec expiration configurable
- CORS configurÃ© pour le frontend
- Validation des fichiers audio uploadÃ©s
